{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import gc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from utils import *\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "from model.predictor import Predictor\n",
    "from model.sampler import Sampler\n",
    "from torch_geometric.utils import degree\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from data_process import smile_to_graph, read_smiles, read_interactions, generate_node_subgraphs, read_network\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from train_eval import train, test, eval\n",
    "import random\n",
    "from main import *\n",
    "import pdb\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description='TIGER')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "args.model_name = 'TIGER'\n",
    "args.dataset = 'drugbank'\n",
    "args.folds = 5\n",
    "args.layer = 1\n",
    "args.predictor_lr = 0.001\n",
    "args.sampler_lr = 0.1\n",
    "args.weight_decay = 0.0001\n",
    "args.batch_size = 128\n",
    "args.epoch = 50\n",
    "# args.extractor = 'khop-subtree'\n",
    "args.extractor = 'RL'\n",
    "args.graph_fixed_num = 1\n",
    "args.khop = 1\n",
    "args.fixed_num = 32\n",
    "args.d_dim = 64\n",
    "args.fixed_num = 32\n",
    "args.num_heads = 4\n",
    "args.max_smiles_degree = 300\n",
    "args.max_graph_degree = 600\n",
    "args.dropout = 0.2\n",
    "args.k_step = 10\n",
    "args.sub_coeff = 0.1\n",
    "args.mi_coeff = 0.1\n",
    "args.s_type = 'random'\n",
    "args.pos = 1\n",
    "args.neg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12fcffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read /bigdat2/user/xiejc/zhangc/dataset/TIGER/dataset/drugbank/drug_smiles.txt!\n",
      "10630\n",
      "10630\n"
     ]
    }
   ],
   "source": [
    "dataset = args.dataset\n",
    "data_path = \"/bigdat2/user/xiejc/zhangc/dataset/TIGER/dataset/\" + dataset + \"/\"\n",
    "ligands = read_smiles(os.path.join(data_path, \"drug_smiles.txt\"))\n",
    "smile_graph, num_rel_mol_update, max_smiles_degree = smile_to_graph(data_path, ligands)\n",
    "interactions_label, all_contained_drgus = read_interactions(os.path.join(data_path, \"ddi.txt\"), smile_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3552fab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  819,   758,     1,     1],\n",
       "       [  822,   758,     1,     1],\n",
       "       [  826,   758,     1,     1],\n",
       "       ...,\n",
       "       [ 8311, 38519,     1,     0],\n",
       "       [29607, 26875,     1,     0],\n",
       "       [32738,  6294,     1,     0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65378f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nodes = defaultdict(list)\n",
    "for i, (drug1, drug2, _, label) in enumerate(interactions_label):\n",
    "    nodes[drug1].append((drug2, label))\n",
    "    nodes[drug2].append((drug1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 13128 val size: 3428 test size: 3973\n",
      "(6939, 6189) (1724, 1704) (1954, 2019)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "labels = {}\n",
    "for node in nodes:\n",
    "    labels[node] = {0:0, 1:1}\n",
    "\n",
    "for node in nodes:\n",
    "    for _, label in nodes[node]:\n",
    "        labels[node][label] += 1\n",
    "\n",
    "train_nodes = set()\n",
    "\n",
    "train_size = 0.6*len(interactions_label)\n",
    "val_size = 0.2*len(interactions_label)\n",
    "test_size = 0.2*len(interactions_label)\n",
    "\n",
    "train_s = 0\n",
    "val_s = 0\n",
    "test_s = 0\n",
    "\n",
    "t = 0\n",
    "f = 0\n",
    "test_node = set()\n",
    "while(test_s < test_size):\n",
    "    node = random.choice(list(nodes.keys()))\n",
    "    if node in test_node:\n",
    "        continue\n",
    "    if t>f and labels[node][0] < labels[node][1]:\n",
    "        continue\n",
    "    if f>t and labels[node][1] < labels[node][0]:\n",
    "        continue\n",
    "    t += labels[node][1]\n",
    "    f += labels[node][0]\n",
    "    test_s += (labels[node][1]+labels[node][0])\n",
    "    test_node.add(node)\n",
    "\n",
    "t = 0\n",
    "f = 0\n",
    "val_node = set()\n",
    "while(val_s < val_size):\n",
    "    node = random.choice(list(nodes.keys()))\n",
    "    if node in test_node or node in val_node:\n",
    "        continue\n",
    "    if t>f and labels[node][0] < labels[node][1]:\n",
    "        continue\n",
    "    if f>t and labels[node][1] < labels[node][0]:\n",
    "        continue\n",
    "    t += labels[node][1]\n",
    "    f += labels[node][0]\n",
    "    val_s += (labels[node][1]+labels[node][0])\n",
    "    val_node.add(node)\n",
    "\n",
    "for node in nodes:\n",
    "    if node in test_node or node in val_node:\n",
    "        continue\n",
    "    train_nodes.add(node)\n",
    "\n",
    "test_set = set()\n",
    "for node in test_node:\n",
    "    for p in nodes[node]:\n",
    "        if (p[0], node, p[1]) in test_set or (node, p[0], p[1]) in test_set:\n",
    "            continue\n",
    "        test_set.add((node, p[0], p[1]))\n",
    "\n",
    "val_set = set()\n",
    "for node in val_node:\n",
    "    for p in nodes[node]:\n",
    "        if (p[0], node, p[1]) in val_set or (node, p[0], p[1]) in val_set:\n",
    "            continue\n",
    "        if (p[0], node, p[1]) in test_set or (node, p[0], p[1]) in test_set:\n",
    "            continue \n",
    "        val_set.add((node, p[0], p[1]))\n",
    "\n",
    "train_set = set()\n",
    "for node in train_nodes:\n",
    "    for p in nodes[node]:\n",
    "        if (p[0], node, p[1]) in train_set or (node, p[0], p[1]) in train_set:\n",
    "            continue\n",
    "        if (p[0], node, p[1]) in val_set or (node, p[0], p[1]) in val_set:\n",
    "            continue\n",
    "        if (p[0], node, p[1]) in test_set or (node, p[0], p[1]) in test_set:\n",
    "            continue \n",
    "        train_set.add((node, p[0], p[1]))\n",
    "\n",
    "updated_train_node = set()\n",
    "for u,v, label in train_set:\n",
    "    updated_train_node.add(u)\n",
    "    updated_train_node.add(v)\n",
    "\n",
    "to_remove = set()\n",
    "for tri in test_set:\n",
    "    if tri[0] in updated_train_node and tri[1] in updated_train_node:\n",
    "        to_remove.add(tri)\n",
    "test_set = test_set - to_remove\n",
    "\n",
    "to_remove = set()\n",
    "for tri in val_set:\n",
    "    if tri[0] in updated_train_node and tri[1] in updated_train_node:\n",
    "        to_remove.add(tri)\n",
    "val_set = val_set - to_remove\n",
    "\n",
    "print(f'train size: {len(train_set)}', f'val size: {len(val_set)}', f'test size: {len(test_set)}')\n",
    "\n",
    "def f(data):\n",
    "    t, f = 0, 0\n",
    "    for u,v, label in data:\n",
    "        if label == 1:\n",
    "            t += 1\n",
    "        else:\n",
    "            f += 1\n",
    "    return t, f\n",
    "\n",
    "print(f(train_set), f(val_set), f(test_set))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dadab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(interactions_label, data_set):\n",
    "    index = []\n",
    "    for u,v,label in data_set:\n",
    "\n",
    "        matches = np.all(interactions_label == [u,v,1,label], axis=1)\n",
    "        indices = np.where(matches)[0]\n",
    "        if len(indices) > 0:\n",
    "            index.append(indices[0])\n",
    "        else:\n",
    "            matches = np.all(interactions_label == [v,u,1,label], axis=1)\n",
    "            indices = np.where(matches)[0]\n",
    "            index.append(indices[0])\n",
    "    return index\n",
    "\n",
    "train_index = get_index(interactions_label, train_set)\n",
    "val_index = get_index(interactions_label, val_set)\n",
    "test_index = get_index(interactions_label, test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a92333e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = interactions_label[train_index]\n",
    "val_data = interactions_label[val_index]\n",
    "test_data = interactions_label[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "864eddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both seen: 0 both unseen: 210 one seen: 3218\n"
     ]
    }
   ],
   "source": [
    "updated_train_node = set()\n",
    "for u,v,_, label in train_data:\n",
    "    updated_train_node.add(u)\n",
    "    updated_train_node.add(v)\n",
    "\n",
    "t1, t2, t3 = 0, 0, 0\n",
    "for tri in val_data:\n",
    "    if tri[0] in updated_train_node and tri[1] in updated_train_node:\n",
    "        t1 += 1\n",
    "    elif tri[0] not in updated_train_node and tri[1] not in updated_train_node:\n",
    "        t2 += 1\n",
    "    else:\n",
    "        t3 += 1\n",
    "\n",
    "print('both seen:', t1, 'both unseen:', t2, 'one seen:', t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "data = {'train': [torch.tensor(train_index)],\n",
    "        'val': [torch.tensor(val_index)],\n",
    "        'test': [torch.tensor(test_index)]}\n",
    "\n",
    "with open('/home/xiejc/Code/TIGER/RL/data/drugbank/inductive_split.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72df77f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([    0,     1,     2,  ..., 20800, 20801, 20802]), tensor([    0,     1,     2,  ..., 20803, 20805, 20807]), tensor([    0,     1,     3,  ..., 20805, 20806, 20807]), tensor([    4,     8,    11,  ..., 20805, 20806, 20807]), tensor([    2,     5,     6,  ..., 20802, 20804, 20806])], [array([   14,    15,    25, ..., 20797, 20804, 20806]), array([    8,    11,    13, ..., 20791, 20800, 20802]), array([    2,     5,     6, ..., 20798, 20799, 20801]), array([    0,     1,     3, ..., 20779, 20786, 20792]), array([    4,    18,    27, ..., 20803, 20805, 20807])], [array([    4,    18,    27, ..., 20803, 20805, 20807]), array([   14,    15,    25, ..., 20797, 20804, 20806]), array([    8,    11,    13, ..., 20791, 20800, 20802]), array([    2,     5,     6, ..., 20798, 20799, 20801]), array([    0,     1,     3, ..., 20779, 20786, 20792])])\n"
     ]
    }
   ],
   "source": [
    "def split_fold(folds, dataset, labels, scenario_type='random'):\n",
    "\n",
    "    test_indices, train_indices, val_indices = [], [], []\n",
    "\n",
    "    if scenario_type == 'random':\n",
    "        skf = StratifiedKFold(folds, shuffle=True, random_state=2023)\n",
    "        train_indices, test_indices, val_indices = k_fold(dataset, skf, folds, labels)\n",
    "\n",
    "    return train_indices, test_indices, val_indices\n",
    "\n",
    "tmp = split_fold(5, interactions_label[:,:2], interactions_label[:,3])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dd5b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read /bigdat2/user/xiejc/zhangc/dataset/TIGER/dataset/drugbank/drug_smiles.txt!\n",
      "load drug smiles graphs!!\n",
      "load networks !!\n",
      "load DDI samples!!\n",
      "10630\n",
      "10630\n",
      "generate subgraphs!!\n",
      "{'num_nodes': 391116, 'num_rel_mol': 133, 'num_rel_graph': 71, 'num_interactions': 20808, 'num_drugs_DDI': 1052, 'max_degree_graph': 7, 'max_degree_node': 69}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels, smile_graph, node_graph, dataset_statistics, adj_matrix, edge_rel = load_data(args)\n",
    "\n",
    "edge_index = torch.tensor(adj_matrix).T.cuda()\n",
    "edge_rel = torch.tensor(edge_rel).cuda()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "setup_seed(42)\n",
    "\n",
    "tmp = list(zip(*split_fold(5, data, labels, args.s_type)))\n",
    "train_idx, test_idx, val_idx = tmp[0]\n",
    "\n",
    "# train_idx = train_idx.numpy()\n",
    "\n",
    "train_data = DTADataset(x=data[train_idx], y=labels[train_idx], sub_graph=node_graph, smile_graph=smile_graph)\n",
    "test_data = DTADataset(x=data[test_idx], y=labels[test_idx], sub_graph=node_graph, smile_graph=smile_graph)\n",
    "eval_data = DTADataset(x=data[val_idx], y=labels[val_idx], sub_graph=node_graph, smile_graph=smile_graph)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=False, collate_fn=collate) \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, collate_fn=collate) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False, collate_fn=collate) \n",
    "eval_loader = torch.utils.data.DataLoader(eval_data, batch_size=args.batch_size, shuffle=False, collate_fn=collate) \n",
    "\n",
    "DDI_predictor, DDI_sampler, predictor_optim, sampler_optim = init_model(args, dataset_statistics)\n",
    "DDI_predictor.to(device)\n",
    "DDI_sampler.to(device)\n",
    "DDI_predictor.reset_parameters()\n",
    "\n",
    "# DDI_predictor.load_state_dict(torch.load('/home/xiejc/Code/TIGER/RL/best_save/tiger/drugbank/RL/fold_0/0.00000/DDI_predictor.pt'))\n",
    "# DDI_predictor.load_state_dict(torch.load('/home/xiejc/Code/TIGER/RL/best_save/tiger/drugbank/RL/1.0-1.0-s2/fold_0/67.35455/DDI_predictor.pt'))\n",
    "DDI_predictor.load_state_dict(torch.load('/home/xiejc/Code/TIGER/RL/best_save/tiger/drugbank/khop-subtree/fold_0/0.87003/DDI_predictor.pt'))\n",
    "# DDI_sampler.load_state_dict(torch.load('/home/xiejc/Code/TIGER/RL/best_save/tiger/drugbank/RL/1.0-1.0-s2/fold_0/67.35455/DDI_sampler.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a185d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/xiejc/Code/TIGER/RL/data/drugbank/khop-subtree/hop_1_old.pkl', 'rb') as f:\n",
    "    h1 = pickle.load(f)\n",
    "\n",
    "with open('/home/xiejc/Code/TIGER/RL/data/drugbank/khop-subtree/hop_1.pkl', 'rb') as f:\n",
    "    h2 = pickle.load(f)\n",
    "\n",
    "\n",
    "d1, d2 = data[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69b65ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    49,    819,   3906,  10879,  10886,  10887,  16113,  32172,  39877,\n",
       "        101648, 161862, 161868, 161869, 161874, 161875, 161877, 161880, 161884,\n",
       "        161885, 161894, 161899, 161903, 161906, 161907, 161911, 161912, 161913,\n",
       "        161914, 161916, 161940,      9,     60,     84,    758,    759,    761,\n",
       "           762,    763,    764,    767,    771,    772,    774,    776,    780,\n",
       "           784,    786,    788,    789,    791,    793,    804,    830,    833,\n",
       "           834,    835,    837,    839])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1[(d1, d2)].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ae90c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     9,     49,     60,     84,    758,    759,    761,    762,    763,\n",
       "           764,    767,    771,    772,    774,    776,    780,    784,    786,\n",
       "           788,    789,    791,    793,    804,    819,    830,    833,    834,\n",
       "           835,    837,    839,   3906,  10879,  10886,  10887,  16113,  32172,\n",
       "         39877, 101648, 161862, 161868, 161869, 161874, 161875, 161877, 161880,\n",
       "        161884, 161885, 161894, 161899, 161903, 161906, 161907, 161911, 161912,\n",
       "        161913, 161914, 161916, 161940])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2[(d1, d2)].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aeda71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = list(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in range(len(train_loaders)):\n",
    "    data_subgraph = train_loaders[i][2]\n",
    "    nodes_with_id_1 = torch.where(data_subgraph.id == 1)[0]\n",
    "\n",
    "    neighbors = []\n",
    "    for node in nodes_with_id_1:\n",
    "        src_neighbors = data_subgraph.edge_index[1][data_subgraph.edge_index[0] == node]\n",
    "        dst_neighbors = data_subgraph.edge_index[0][data_subgraph.edge_index[1] == node]\n",
    "        node_neighbors = torch.cat([src_neighbors, dst_neighbors]).unique()\n",
    "        neighbors.append(node_neighbors)\n",
    "    print(data_subgraph.x)\n",
    "    print(data_subgraph.edge_index)\n",
    "    print(train_loaders[i][3])\n",
    "    neighbors = torch.cat(neighbors).unique()\n",
    "    print(neighbors)\n",
    "    print(len(neighbors))\n",
    "    asfdasf\n",
    "    s.append(len(neighbors))\n",
    "\n",
    "print(max(s), min(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024b1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, accuracy_score, auc\n",
    "def get_score(label_all, prob_all):\n",
    "\n",
    "    predicts_label = [1 if prob >= 0.5 else 0 for prob in prob_all]\n",
    "\n",
    "    acc = accuracy_score(label_all, predicts_label)\n",
    "    f1 = f1_score(label_all, predicts_label)\n",
    "    auroc = roc_auc_score(label_all, prob_all)\n",
    "    p, r, t = precision_recall_curve(label_all, prob_all)\n",
    "    auprc = auc(r, p)\n",
    "\n",
    "    return acc, f1, auroc, auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea363fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:55<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Model: acc: 0.8804, f1: 0.8888, auroc: 0.9500, auprc: 0.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = []\n",
    "label = []\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "num_nodes = dataset_statistics['num_nodes']\n",
    "\n",
    "for data in tqdm(train_loader):\n",
    "    data_mol1 = data[0].cuda()\n",
    "    data_mol2 = data[1].cuda()\n",
    "    data_subgraph = data[2].cuda()\n",
    "    data_idx = data[3].cuda() \n",
    "\n",
    "    predicts, loss = DDI_predictor(data_mol1, data_mol2, data_subgraph)\n",
    "\n",
    "    pred1.append(predicts)\n",
    "\n",
    "    label.append(data_mol1.y)\n",
    "\n",
    "\n",
    "label_all = torch.concat(label).cpu().detach().numpy()\n",
    "pred1_all = torch.concat(pred1).cpu().detach().numpy()\n",
    "\n",
    "acc1, f11, auc1, aupr1 = get_score(label_all, pred1_all)\n",
    "print('Default Model: acc: %.4f, f1: %.4f, auroc: %.4f, auprc: %.4f' % (acc1, f11, auc1, aupr1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001620f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [12:38<00:00,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Model: acc: 0.5706, f1: 0.5940, auroc: 0.6051, auprc: 0.6070\n",
      "RL Model: acc: 0.5990, f1: 0.6266, auroc: 0.6378, auprc: 0.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = []\n",
    "pred2 = []\n",
    "label = []\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "num_nodes = dataset_statistics['num_nodes']\n",
    "\n",
    "for data in tqdm(train_loader):\n",
    "    data_mol1 = data[0].cuda()\n",
    "    data_mol2 = data[1].cuda()\n",
    "    data_subgraph = data[2].cuda()\n",
    "    data_idx = data[3].cuda() \n",
    "\n",
    "    selected_subgraph_list, batch = DDI_sampler.generate_default_subgraph(data_idx, edge_index, edge_rel)\n",
    "    selected_subgraph_list = selected_subgraph_list.cuda()\n",
    "    batch = batch.cuda()\n",
    "    pred_default = DDI_predictor.pred(data_mol1, data_mol2, data_subgraph, batch)\n",
    "\n",
    "    pred1.append(pred_default)\n",
    "\n",
    "    embeddings = DDI_predictor.drug_node_feature.node_encoder(torch.tensor(range(num_nodes)).cuda())\n",
    "    selected_subgraph_list, batch = DDI_sampler.predict(data_idx, edge_index, edge_rel, embeddings) \n",
    "    selected_subgraph_list = selected_subgraph_list.cuda()\n",
    "    batch = batch.cuda()\n",
    "    \n",
    "    reward_batch, predicts = DDI_predictor.get_reward(data_mol1, data_mol2, selected_subgraph_list, batch, pred_default)\n",
    "    total_reward += torch.sum(reward_batch).item()\n",
    "\n",
    "    pred2.append(predicts)\n",
    "    label.append(data_mol1.y)\n",
    "\n",
    "\n",
    "label_all = torch.concat(label).cpu().detach().numpy()\n",
    "pred1_all = torch.concat(pred1).cpu().detach().numpy()\n",
    "pred2_all = torch.concat(pred2).cpu().detach().numpy()\n",
    "\n",
    "acc1, f11, auc1, aupr1 = get_score(label_all, pred1_all)\n",
    "acc2, f12, auc2, aupr2 = get_score(label_all, pred2_all)\n",
    "print('Default Model: acc: %.4f, f1: %.4f, auroc: %.4f, auprc: %.4f' % (acc1, f11, auc1, aupr1))\n",
    "print('RL Model: acc: %.4f, f1: %.4f, auroc: %.4f, auprc: %.4f' % (acc2, f12, auc2, aupr2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f2da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9665], device='cuda:0') tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "\n",
    "data_mol1 = train_loaders[idx][0].cuda()\n",
    "data_mol2 = train_loaders[idx][1].cuda()\n",
    "data_subgraph = train_loaders[idx][2].cuda()\n",
    "data_idx = train_loaders[idx][3].cuda() # batch_size * 2\n",
    "\n",
    "DDI_predictor.eval()\n",
    "DDI_sampler.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch = torch.tensor(range(data_idx.shape[0])).cuda()\n",
    "    pred_default = DDI_predictor.pred(data_mol1, data_mol2, data_subgraph, batch)\n",
    "\n",
    "print(pred_default, data_mol1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e413b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "src, tgt = data_subgraph.edge_index\n",
    "src = src.cpu().detach().numpy().tolist()\n",
    "tgt = tgt.cpu().detach().numpy().tolist()\n",
    "b = list(zip(src, tgt))\n",
    "print(len(b))\n",
    "print(len(set(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a27bf6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "src, tgt = G_sub.edge_index\n",
    "src = src.cpu().detach().numpy().tolist()\n",
    "tgt = tgt.cpu().detach().numpy().tolist()\n",
    "a = list(zip(src, tgt))\n",
    "print(len(a))\n",
    "print(len(set(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe8c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9059], device='cuda:0') tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree, subgraph, k_hop_subgraph\n",
    "\n",
    "idx = 200\n",
    "\n",
    "data_mol1 = train_loaders[idx][0].cuda()\n",
    "data_mol2 = train_loaders[idx][1].cuda()\n",
    "data_subgraph = train_loaders[idx][2].cuda()\n",
    "data_idx = train_loaders[idx][3].cuda() # batch_size * 2\n",
    "\n",
    "DDI_predictor.eval()\n",
    "DDI_sampler.eval()\n",
    "\n",
    "x = data_subgraph.x\n",
    "\n",
    "edge_index2, edge_rel2 = subgraph(x, edge_index, edge_rel, relabel_nodes=True)\n",
    "\n",
    "mapping_id = torch.zeros(len(x), dtype=torch.long)\n",
    "mapping_id[torch.where(x == data_idx[0][0])[0]] = 1\n",
    "mapping_id[torch.where(x == data_idx[0][1])[0]] = 1\n",
    "\n",
    "G_sub = DATA.Data(x=x,\n",
    "            edge_index=edge_index2,\n",
    "            id=mapping_id,\n",
    "            rel_index=edge_rel2,\n",
    "            sp_edge_index=edge_index2,\n",
    "            sp_value=torch.ones(edge_index2.size(1), dtype=torch.float),\n",
    "            sp_edge_rel=edge_rel2\n",
    "        )\n",
    "\n",
    "G_sub = Batch.from_data_list([G_sub]).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch = torch.tensor(range(data_idx.shape[0])).cuda()\n",
    "    pred_default = DDI_predictor.pred(data_mol1, data_mol2, G_sub, batch)\n",
    "\n",
    "print(pred_default, data_mol1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0e7c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[64], edge_index=[2, 246], id=[64], rel_index=[246], sp_edge_index=[2, 246], sp_value=[246], sp_edge_rel=[246]),\n",
       " Data(x=[65], edge_index=[2, 250], id=[65], rel_index=[250], sp_edge_index=[2, 250], sp_value=[250], sp_edge_rel=[250]),\n",
       " Data(x=[66], edge_index=[2, 254], id=[66], rel_index=[254], sp_edge_index=[2, 254], sp_value=[254], sp_edge_rel=[254]),\n",
       " Data(x=[67], edge_index=[2, 258], id=[67], rel_index=[258], sp_edge_index=[2, 258], sp_value=[258], sp_edge_rel=[258]),\n",
       " Data(x=[68], edge_index=[2, 262], id=[68], rel_index=[262], sp_edge_index=[2, 262], sp_value=[262], sp_edge_rel=[262]),\n",
       " Data(x=[69], edge_index=[2, 268], id=[69], rel_index=[268], sp_edge_index=[2, 268], sp_value=[268], sp_edge_rel=[268]),\n",
       " Data(x=[70], edge_index=[2, 272], id=[70], rel_index=[272], sp_edge_index=[2, 272], sp_value=[272], sp_edge_rel=[272]),\n",
       " Data(x=[71], edge_index=[2, 276], id=[71], rel_index=[276], sp_edge_index=[2, 276], sp_value=[276], sp_edge_rel=[276]),\n",
       " Data(x=[72], edge_index=[2, 280], id=[72], rel_index=[280], sp_edge_index=[2, 280], sp_value=[280], sp_edge_rel=[280]),\n",
       " Data(x=[73], edge_index=[2, 284], id=[73], rel_index=[284], sp_edge_index=[2, 284], sp_value=[284], sp_edge_rel=[284])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_subgraph_list.to_data_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03732c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['((0, 27743), 0.0088, -0.9665)', '((0, 27668), 0.0079, -0.9664)', '((0, 27680), 0.0080, -0.9664)', '((0, 151057), 0.0083, -0.9664)', '((0, 151084), 0.0082, -0.9664)', '((0, 25412), 0.0092, -0.9664)', '((0, 151058), 0.0086, -0.9664)', '((0, 27692), 0.0090, -0.9664)', '((0, 27687), 0.0090, -0.9664)', '((0, 27858), 0.0088, -0.9664)']\n",
      "-9.66413688659668\n",
      "tensor([9.8239e-05, 1.0850e-04, 1.1072e-04, 1.1109e-04, 1.1802e-04, 1.3134e-04,\n",
      "        1.2990e-04, 1.8765e-04, 1.9280e-04, 1.7292e-04], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "num_nodes = dataset_statistics['num_nodes']\n",
    "with torch.no_grad():\n",
    "    embeddings = DDI_predictor.drug_node_feature.node_encoder(torch.tensor(range(num_nodes)).cuda())\n",
    "selected_subgraph_list, selected_subgraph_prob_list, batch, tmp = DDI_sampler(data_idx, edge_index, edge_rel, embeddings, data_subgraph)\n",
    "\n",
    "selected_subgraph_list = selected_subgraph_list.cuda()\n",
    "batch = batch.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reward_batch, predicts = DDI_predictor.get_reward(data_mol1, data_mol2, selected_subgraph_list, batch, pred_default)\n",
    "\n",
    "a = [(tmp[i], selected_subgraph_prob_list[i].item(), reward_batch[i].item()) for i in range(len(tmp))]\n",
    "print([f\"({x[0]}, {x[1]:.4f}, {x[2]:.4f})\" for x in a])\n",
    "print(torch.sum(reward_batch).item())\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52752d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5])\n",
    "b = torch.tensor([3,2,1,7,6])\n",
    "\n",
    "c = torch.cat([a,b], dim=0)\n",
    "c = torch.unique(c, dim=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d0556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([213, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree, subgraph, k_hop_subgraph\n",
    "\n",
    "graph_embeddings = torch.concat((embeddings, DDI_sampler.done_embedding.weight), dim=0) \n",
    "\n",
    "current_nodes = data_idx[0]\n",
    "\n",
    "for _ in range(1):\n",
    "    current_neighbors = DDI_sampler.get_neighbors(current_nodes, edge_index) \n",
    "    mask = ~torch.isin(current_neighbors, current_nodes)\n",
    "    current_neighbors = current_neighbors[mask]\n",
    "\n",
    "    neighbors_embeddings =  graph_embeddings[current_neighbors]\n",
    "    k_embeddings = graph_embeddings[current_nodes].mean(dim=0)\n",
    "\n",
    "    logits = DDI_sampler.prior(k_embeddings.expand_as(neighbors_embeddings), neighbors_embeddings)\n",
    "\n",
    "    print(neighbors_embeddings.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3e5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0830e-10, 6.3097e-10, 2.0367e-10, 6.0915e-11, 2.9689e-09, 6.3208e-11,\n",
       "        7.5545e-11, 9.1292e-04, 2.6761e-06, 5.5650e-11, 5.1834e-10, 2.8352e-10,\n",
       "        1.3596e-09, 3.6235e-11, 2.6743e-10, 3.2621e-10, 3.9418e-11, 6.6574e-11,\n",
       "        8.5086e-11, 7.7675e-11, 4.3505e-10, 7.8275e-09, 1.9513e-10, 4.6439e-10,\n",
       "        6.1970e-11, 1.7582e-10, 1.8908e-08, 1.5779e-10, 8.2300e-11, 1.3202e-10,\n",
       "        5.6626e-11, 2.6970e-10, 2.0408e-09, 2.5742e-10, 6.8789e-08, 4.3487e-10,\n",
       "        2.2408e-10, 1.1551e-10, 5.9214e-11, 4.3066e-10, 7.2286e-11, 4.4758e-10,\n",
       "        1.4138e-03, 1.5043e-07, 2.6613e-09, 3.6469e-10, 5.1665e-05, 2.0351e-10,\n",
       "        7.3577e-11, 3.1566e-09, 2.4525e-10, 4.9033e-11, 2.2919e-08, 4.8477e-11,\n",
       "        7.5948e-11, 1.4439e-10, 2.4066e-10, 1.7304e-10, 2.5364e-09, 3.8400e-09,\n",
       "        5.4374e-11, 8.3430e-11, 2.4670e-10, 6.0068e-11, 8.0299e-11, 3.3665e-10,\n",
       "        1.2282e-10, 1.8414e-10, 1.0142e-10, 1.7689e-10, 6.3985e-11, 1.7394e-10,\n",
       "        1.3243e-10, 1.3957e-10, 9.5974e-11, 3.7813e-11, 6.7495e-10, 8.8385e-11,\n",
       "        6.8703e-11, 2.5751e-10, 9.9762e-01, 9.6600e-11, 6.7150e-11, 1.9483e-10,\n",
       "        9.2103e-11, 4.9908e-10, 9.0334e-11, 8.1714e-11, 1.0376e-10, 9.4959e-11,\n",
       "        7.3678e-10, 4.7758e-10, 1.9453e-10, 1.2090e-10, 3.2843e-10, 4.7814e-11,\n",
       "        9.0361e-11, 9.9343e-10, 7.2965e-11, 8.7275e-11, 7.6057e-11, 1.3216e-10,\n",
       "        5.4787e-10, 1.4801e-10, 5.6188e-11, 8.9959e-11, 1.7369e-10, 6.4964e-11,\n",
       "        4.7046e-11, 9.4065e-11, 1.4938e-10, 8.9872e-11, 1.1052e-10, 1.2876e-10,\n",
       "        8.1939e-11, 1.8749e-10, 6.4834e-11, 1.4749e-10, 5.4458e-11, 5.0926e-09,\n",
       "        1.7697e-10, 1.1462e-10, 1.9935e-10, 7.5037e-11, 1.2488e-10, 1.3659e-10,\n",
       "        1.1922e-10, 1.0882e-10, 1.0673e-10, 1.9191e-10, 4.2461e-11, 1.2341e-10,\n",
       "        7.5244e-10, 2.2748e-10, 8.8984e-11, 1.1732e-10, 1.4002e-10, 4.9749e-10,\n",
       "        8.9987e-11, 1.4328e-10, 6.0517e-11, 1.0331e-10, 4.7211e-11, 1.6648e-10,\n",
       "        1.0872e-09, 5.2379e-11, 1.5897e-10, 1.1732e-10, 1.2822e-10, 1.0836e-10,\n",
       "        3.0821e-10, 8.4867e-11, 1.6690e-10, 5.2809e-11, 1.2285e-10, 9.4334e-11,\n",
       "        1.3867e-07, 1.0078e-10, 3.8256e-11, 1.7843e-10, 3.1944e-10, 8.8413e-11,\n",
       "        3.7898e-09, 6.7420e-11, 1.8310e-10, 1.3195e-10, 1.1623e-10, 1.6166e-09,\n",
       "        2.4523e-10, 2.2338e-10, 5.7347e-11, 8.3176e-11, 3.7292e-11, 3.0499e-09,\n",
       "        2.2120e-10, 2.0084e-10, 1.2478e-10, 4.3180e-10, 3.9448e-10, 1.5598e-10,\n",
       "        1.6137e-10, 1.7187e-09, 4.6924e-11, 2.8002e-10, 8.2179e-11, 6.2617e-11,\n",
       "        7.6255e-11, 1.1062e-10, 6.5392e-11, 5.7275e-11, 4.9831e-11, 1.0628e-10,\n",
       "        2.3638e-10, 5.6083e-11, 9.5563e-11, 1.2563e-10, 1.2586e-10, 1.5935e-10,\n",
       "        1.5899e-10, 2.3439e-10, 6.8716e-11, 7.6701e-09, 9.1840e-11, 4.6084e-11,\n",
       "        4.8981e-11, 1.0315e-10, 1.6839e-10, 2.0386e-10, 6.9043e-11, 1.9486e-10,\n",
       "        1.2237e-10, 1.0511e-10, 2.0091e-10], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832a2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9395, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = k_embeddings.expand_as(neighbors_embeddings)\n",
    "e2 = neighbors_embeddings\n",
    "\n",
    "e3 = DDI_sampler.prior.fc1(torch.cat((e1, e2), dim=-1))\n",
    "e = e1 + e3\n",
    "\n",
    "e_l1 = DDI_sampler.prior.fc_layers[0](e)\n",
    "e_l2 = DDI_sampler.prior.fc_layers[1](e_l1)\n",
    "e_l3 = DDI_sampler.prior.fc_layers[2](e_l2)\n",
    "e_l4 = DDI_sampler.prior.fc_layers[3](e_l3).squeeze()\n",
    "e_l4[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4100, -0.5864, -0.4886, -0.5318,  0.4054,  0.4538, -0.4167,  0.5638,\n",
       "         -0.4315,  0.4092,  0.4140, -0.5129, -0.5220,  0.5087, -0.4700,  0.4654,\n",
       "          0.5506, -0.3612,  0.4555,  0.3850,  0.4648, -0.4004, -0.4736, -0.5325,\n",
       "          0.3799,  0.5322, -0.5124, -0.4700, -0.4387, -0.4650,  0.3855, -0.3797]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDI_sampler.prior.fc_layers[3].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8b081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9748, -0.4366, -0.6336, -0.6649,  0.9594,  0.9516, -0.4009,  0.4172,\n",
       "         -0.3794,  0.9258,  0.6849, -0.7392, -0.5632,  0.9083, -0.8041,  0.6441,\n",
       "          0.9533, -0.9631,  0.8250,  0.4897,  0.5320, -0.9417, -0.9602, -0.8695,\n",
       "          0.9606,  0.4458, -0.9518, -0.8146, -0.9534, -0.3829,  0.9191, -0.9409],\n",
       "        [-0.8228,  0.9628,  0.9647,  0.9706, -0.8601, -0.8854,  0.8317, -0.9705,\n",
       "          0.9311, -0.8923, -0.9306,  0.5511,  0.9716, -0.8803,  0.7787, -0.9118,\n",
       "         -0.7977,  0.5250, -0.5871, -0.9763, -0.9459,  0.7911,  0.8878,  0.7249,\n",
       "         -0.7988, -0.9823,  0.7826,  0.9244,  0.2728,  0.9364, -0.4391,  0.4792]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_l3[80:82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cdfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6000, 0.5000, 0.3000, 2.2000, 1.8000, 1.3000, 0.7000, 1.7000, 0.9000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "reward_all = []\n",
    "batch = torch.tensor([0,0,0,1,1,1,1,2,2])\n",
    "reward_batch = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "for b in torch.unique(batch):\n",
    "    idx = (batch == b).nonzero(as_tuple=True)[0]\n",
    "    batch_reward = reward_batch[idx]\n",
    "    reward = torch.zeros(batch_reward.size(), device=batch_reward.device)\n",
    "    R = 0\n",
    "    n = batch_reward.size(0) - 1\n",
    "    for i, r in enumerate(batch_reward.flip(0)):\n",
    "        R = r + 1 * R\n",
    "        reward[n-i] = R\n",
    "    reward_all.append(reward)\n",
    "reward_batch = torch.concat(reward_all)\n",
    "\n",
    "print(reward_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
